import os
import cv2
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

#########################################
# 1. RUTAS Y CARGA
#########################################

base_dir = os.getcwd()
data_folder = os.path.join(base_dir, "DATASET")

class_folders = os.listdir(data_folder)
images = []
labels = []

for cls in class_folders:
    cls_path = os.path.join(data_folder, cls)
    for f in os.listdir(cls_path):
        img_path = os.path.join(cls_path, f)
        img = cv2.imread(img_path)
        images.append(img)
        labels.append(cls)

#########################################
# 2. PREPROCESSING
#########################################

def preprocessing(images, labels):
    target_size = (128, 128)

    X = [cv2.resize(img, target_size) for img in images]
    X = np.array(X, dtype="float32") / 255.0

    le = LabelEncoder()
    y = le.fit_transform(labels)
    y = to_categorical(y)

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

    return (X_train, y_train, X_test, y_test, le.classes_)

#########################################
# 3. TRAINING (MODEL + TRAIN)
#########################################

def build_model(input_shape, num_classes):
    inp = Input(shape=input_shape)
    x = Conv2D(32, (3,3), activation='relu')(inp)
    x = MaxPooling2D()(x)
    x = Conv2D(64, (3,3), activation='relu')(x)
    x = MaxPooling2D()(x)
    x = Flatten()(x)
    out = Dense(num_classes, activation='softmax')(x)
    model = Model(inp, out)
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    return model

def training(X_train, y_train):
    model = build_model(input_shape=(128,128,3), num_classes=y_train.shape[1])
    history = model.fit(X_train, y_train, epochs=10, batch_size=16, validation_split=0.2)
    return model, history

#########################################
# 4. EVALUATION
#########################################

def evaluation(model, history, X_test, y_test, classes):
    # Curvas
    plt.plot(history.history['loss'], label='train')
    plt.plot(history.history['val_loss'], label='val')
    plt.title("Loss")
    plt.legend()
    plt.show()

    plt.plot(history.history['accuracy'], label='train')
    plt.plot(history.history['val_accuracy'], label='val')
    plt.title("Accuracy")
    plt.legend()
    plt.show()

    # Matriz de confusión
    y_pred = model.predict(X_test)
    y_pred_cls = np.argmax(y_pred, axis=1)
    y_test_cls = np.argmax(y_test, axis=1)

    cm = confusion_matrix(y_test_cls, y_pred_cls)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)
    plt.title("Confusion Matrix")
    plt.show()


#########################################
# 5. EJECUCIÓN
#########################################

X_train, y_train, X_test, y_test, classes = preprocessing(images, labels)
model, history = training(X_train, y_train)
evaluation(model, history, X_test, y_test, classes)
